#ä¸¤è¡Œä»£ç æå®šGitHubä¸Šä¼ ï¼
# git config --global http.proxy http://127.0.0.1:7890
# git config --global https.proxy http://127.0.0.1:7890
import torch
import time
# å‡è®¾ä½ çš„ç±»å®šä¹‰åœ¨ multiView_model.py ä¸­ï¼Œå¦‚æœæ–‡ä»¶åä¸åŒè¯·ä¿®æ”¹è¿™é‡Œ
from MVCL.multiView_model import DynamicTrajectoryBranch

def verify_module():
    print("=" * 40)
    print("ğŸš€ å¼€å§‹éªŒè¯ DynamicTrajectoryBranch æ¨¡å—")
    print("=" * 40)

    # 1. å®šä¹‰æ¨¡æ‹Ÿå‚æ•° (æ¨¡æ‹Ÿ WavLM Base çš„è¾“å‡º)
    BATCH_SIZE = 4
    SEQ_LEN = 149   # å‡è®¾éŸ³é¢‘é•¿åº¦å¯¹åº”çš„å¸§æ•°
    INPUT_DIM = 768 # è¾“å…¥ç‰¹å¾ç»´åº¦
    HIDDEN_DIM = 256 # å†…éƒ¨éšè—å±‚ç»´åº¦

    # 2. å®ä¾‹åŒ–æ¨¡å‹
    
    print(f"ğŸ”¨ æ­£åœ¨åˆå§‹åŒ–æ¨¡å‹ (Input={INPUT_DIM}, Hidden={HIDDEN_DIM})...")
    model = DynamicTrajectoryBranch(
        input_dim=INPUT_DIM, 
        hidden_dim=HIDDEN_DIM, 
        num_layers=2
    )

    # 3. æ„é€ ä¼ªé€ è¾“å…¥æ•°æ® (Random Tensor)
    dummy_input = torch.randn(BATCH_SIZE, SEQ_LEN, INPUT_DIM)
    print(f"ğŸ“¥ è¾“å…¥æ•°æ®å½¢çŠ¶: {dummy_input.shape} (B, T, D)")

    # ---------------------------------------------------------
    # æµ‹è¯• A: CPU ç»´åº¦éªŒè¯
    # ---------------------------------------------------------
    print("\n[æµ‹è¯• A] CPU å‰å‘ä¼ æ’­ & ç»´åº¦æ£€æŸ¥...")
    try:
        # å‰å‘ä¼ æ’­
        final_feat, lstm_out = model(dummy_input)
        
        # æ‰“å°è¾“å‡ºå½¢çŠ¶
        print(f"   --> final_feat (å…¨å±€ç‰¹å¾): {final_feat.shape}")
        print(f"   --> lstm_out   (åºåˆ—ç‰¹å¾): {lstm_out.shape}")

        # è‡ªåŠ¨æ–­è¨€æ£€æŸ¥ (Assertion)
        # é¢„æœŸ final_feat: (B, HIDDEN_DIM) -> (4, 256)
        assert final_feat.shape == (BATCH_SIZE, HIDDEN_DIM), \
            f"âŒ å…¨å±€ç‰¹å¾ç»´åº¦é”™è¯¯! é¢„æœŸ {(BATCH_SIZE, HIDDEN_DIM)}, å®é™… {final_feat.shape}"
        
        # é¢„æœŸ lstm_out: (B, T, HIDDEN_DIM * 2) -> (4, 149, 512) (å› ä¸ºæ˜¯åŒå‘ Bi-GRU)
        assert lstm_out.shape == (BATCH_SIZE, SEQ_LEN, HIDDEN_DIM * 2), \
            f"âŒ åºåˆ—ç‰¹å¾ç»´åº¦é”™è¯¯! é¢„æœŸ {(BATCH_SIZE, SEQ_LEN, HIDDEN_DIM * 2)}, å®é™… {lstm_out.shape}"

        print("âœ… CPU ç»´åº¦éªŒè¯é€šè¿‡ï¼é€»è¾‘æ— è¯¯ã€‚")

    except Exception as e:
        print(f"âŒ CPU æµ‹è¯•å¤±è´¥: {e}")
        return # CPU æŒ‚äº†å°±ä¸æµ‹ GPU äº†

    # ---------------------------------------------------------
    # æµ‹è¯• B: GPU (RTX 5070 Ti) å…¼å®¹æ€§éªŒè¯
    # ---------------------------------------------------------
    print("\n[æµ‹è¯• B] GPU (CUDA) å…¼å®¹æ€§æµ‹è¯•...")
    if torch.cuda.is_available():
        try:
            device = torch.device("cuda")
            
            # å°†æ¨¡å‹å’Œæ•°æ®æ¬è¿åˆ° GPU
            model = model.to(device)
            dummy_input_gpu = dummy_input.to(device)
            
            # è®°å½•æ—¶é—´è·‘ä¸€ä¸‹
            start_t = time.time()
            _ = model(dummy_input_gpu)
            end_t = time.time()
            
            print(f"   è®¾å¤‡åç§°: {torch.cuda.get_device_name(0)}")
            print(f"   æ¨ç†è€—æ—¶: {(end_t - start_t) * 1000:.2f} ms")
            print("âœ… GPU è¿è¡ŒæˆåŠŸï¼Blackwell æ¶æ„å…¼å®¹æ€§æ­£å¸¸ã€‚")
            
        except RuntimeError as e:
            print(f"âŒ GPU è¿è¡Œå¤±è´¥ (å¯èƒ½æ˜¯æ˜¾å­˜æˆ–ç‰ˆæœ¬é—®é¢˜): \n{e}")
    else:
        print("âš ï¸ æœªæ£€æµ‹åˆ° GPUï¼Œè·³è¿‡æ­¤æµ‹è¯•ã€‚")

if __name__ == "__main__":
    verify_module()

